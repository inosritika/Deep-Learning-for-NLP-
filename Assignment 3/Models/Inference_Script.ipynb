{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "* Here I have divided the data into train and test for calculating the metrics for test data. If you are providing whole data as test data, then please un-comment the line written below train-test split code. You will get the desired results.\n",
        "* I have saved model for 'BCEWithLogitsLoss as \"model1\" and one based on 'FocalLoss' as \"model2\". While running this code, loss function name should be changed for correct results (make changes in this code - \"loss_type = 'BCEWithLogitsLoss'  # or 'FocalLoss', depending on the model\")"
      ],
      "metadata": {
        "id": "qO-9Iw8lrnci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "MEEA7W3K6Wnv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel"
      ],
      "metadata": {
        "id": "X41CP63ENWV7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]['Title'] + ' ' + self.texts.iloc[idx]['abstractText']\n",
        "        labels = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.FloatTensor(labels)\n",
        "        }"
      ],
      "metadata": {
        "id": "j7rTibam8RQ3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        if self.logits:\n",
        "            BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        else:\n",
        "            BCE_loss = nn.functional.binary_cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        else:\n",
        "            return F_loss"
      ],
      "metadata": {
        "id": "nIekKRtdNlhX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLabelClassifier(nn.Module):\n",
        "    def __init__(self, n_classes, loss_type='BCEWithLogitsLoss', steps_per_epoch=None, n_epochs=3, lr=2e-5):\n",
        "        super(MultiLabelClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.bert.config.hidden_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(1024, n_classes)\n",
        "        )\n",
        "\n",
        "        if loss_type == 'BCEWithLogitsLoss':\n",
        "            self.criterion = nn.BCEWithLogitsLoss()\n",
        "        elif loss_type == 'FocalLoss':\n",
        "            self.criterion = FocalLoss(alpha=1, gamma=2, logits=True, reduce=True)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid loss type provided: choose 'BCEWithLogitsLoss' or 'FocalLoss'\")\n",
        "\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.n_epochs = n_epochs\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return self.classifier(output.pooler_output)"
      ],
      "metadata": {
        "id": "CmORp4AkNe37"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/content/Multi-Label Text Classification Dataset.csv', engine='python', on_bad_lines='skip')\n",
        "df['Title'] = df['Title'].fillna('')\n",
        "df['abstractText'] = df['abstractText'].fillna('')\n",
        "\n",
        "# Define the label mappings\n",
        "label_mappings = {\n",
        "    \"A\": \"Anatomy\",\n",
        "    \"B\": \"Organisms\",\n",
        "    \"C\": \"Diseases\",\n",
        "    \"D\": \"Chemicals and Drugs\",\n",
        "    \"E\": \"Analytical, Diagnostic and Therapeutic Techniques, and Equipment\",\n",
        "    \"F\": \"Psychiatry and Psychology\",\n",
        "    \"G\": \"Phenomena and Processes\",\n",
        "    \"H\": \"Disciplines and Occupations\",\n",
        "    \"I\": \"Anthropology, Education, Sociology, and Social Phenomena\",\n",
        "    \"J\": \"Technology, Industry, and Agriculture\",\n",
        "    \"L\": \"Information Science\",\n",
        "    \"M\": \"Named Groups\",\n",
        "    \"N\": \"Health Care\",\n",
        "    \"Z\": \"Geographicals\"\n",
        "}\n",
        "\n",
        "# Extract the labels for each row and convert them into a list of lists\n",
        "labels = []\n",
        "for index, row in df.iterrows():\n",
        "    row_labels = [label for label, present in row[label_mappings.keys()].items() if present == 1]\n",
        "    labels.append(row_labels)\n",
        "\n",
        "# Encode labels as one-hot vectors\n",
        "mlb = MultiLabelBinarizer()\n",
        "df['one_hot_labels'] = list(mlb.fit_transform(labels))\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[['Title', 'abstractText']], df['one_hot_labels'], test_size=0.1, random_state=42)\n",
        "\n",
        "# NOTE : Above step can be removed if data is only provided for testing and un-commenting below code\n",
        "# x_test = df\n"
      ],
      "metadata": {
        "id": "WbFoiOR88YNv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "test_dataset = TextDataset(x_test, np.array(y_test.tolist()), tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "qHCELYjT6XSH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(labels)  # Fit the mlb instance to labels to set up the classes\n",
        "\n",
        "model_path = '/content/drive/MyDrive/multi_label_text_classification_model1.pth'\n",
        "\n",
        "# Determine the loss type used for training the saved model\n",
        "loss_type = 'BCEWithLogitsLoss'  # or 'FocalLoss', depending on the model\n",
        "\n",
        "model = MultiLabelClassifier(n_classes=len(mlb.classes_), loss_type=loss_type)\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "b3CaMZY46Zzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        preds = torch.sigmoid(outputs).round().int()\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Calculate metrics for each class\n",
        "for i, class_name in enumerate(mlb.classes_):\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels[:, i], all_preds[:, i], average='binary')\n",
        "    print(f\"Class: {class_name} - Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
        "\n",
        "# Calculate micro and macro averages for precision, recall, and F1-score\n",
        "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(all_labels, all_preds, average='micro')\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Micro Average - Precision: {precision_micro}, Recall: {recall_micro}, F1-Score: {f1_micro}\")\n",
        "print(f\"Macro Average - Precision: {precision_macro}, Recall: {recall_macro}, F1-Score: {f1_macro}\")\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Overall Test Accuracy: {overall_accuracy}\")"
      ],
      "metadata": {
        "id": "pPzR6cV26dk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CsxPnOlL6eB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}